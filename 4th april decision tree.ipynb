{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b3c171-adff-480f-bbad-d0262c1f308a",
   "metadata": {},
   "source": [
    "### Q1. Decision Tree Classifier Algorithm:\n",
    "\n",
    "- **Definition:**\n",
    "  - A decision tree is a supervised machine learning algorithm used for both classification and regression.\n",
    "  - It recursively splits the dataset based on features to create a tree-like structure.\n",
    "\n",
    "- **Working:**\n",
    "  - **Step 1:** Select the best feature to split the dataset.\n",
    "  - **Step 2:** Split the dataset into subsets based on the chosen feature.\n",
    "  - **Step 3:** Repeat steps 1 and 2 for each subset (recursion).\n",
    "  - **Step 4:** Stop splitting when a predefined stopping criterion is met.\n",
    "  - **Prediction:** Assign the majority class in the leaf node to instances.\n",
    "\n",
    "### Q2. Mathematical Intuition:\n",
    "\n",
    "- **Information Gain (for Classification):**\n",
    "  - \\( \\text{Information Gain} = \\text{Entropy(parent)} - \\sum_{i} \\left( \\frac{N_i}{N} \\times \\text{Entropy(child}_i) \\right) \\)\n",
    "  - Measures the reduction in entropy after a dataset is split.\n",
    "\n",
    "### Q3. Binary Classification:\n",
    "\n",
    "- **Decision Node:**\n",
    "  - Splits the dataset into two subsets based on a feature.\n",
    "- **Leaf Node:**\n",
    "  - Represents the class label assigned to instances.\n",
    "\n",
    "### Q4. Geometric Intuition:\n",
    "\n",
    "- **Decision Boundaries:**\n",
    "  - Divides feature space into regions, each associated with a class label.\n",
    "  - Axis-aligned splits create rectangles in feature space.\n",
    "\n",
    "### Q5. Confusion Matrix:\n",
    "\n",
    "- **Definition:**\n",
    "  - A table representing the performance of a classification model.\n",
    "  - Rows: Actual classes; Columns: Predicted classes.\n",
    "\n",
    "### Q6. Example Confusion Matrix:\n",
    "\n",
    "\\[\n",
    "\\begin{matrix}\n",
    " & \\text{Predicted: 0} & \\text{Predicted: 1} \\\\\n",
    "\\text{Actual: 0} & \\text{TN} & \\text{FP} \\\\\n",
    "\\text{Actual: 1} & \\text{FN} & \\text{TP} \\\\\n",
    "\\end{matrix}\n",
    "\\]\n",
    "\n",
    "- **Metrics:**\n",
    "  - Precision: \\( \\frac{\\text{TP}}{\\text{TP + FP}} \\)\n",
    "  - Recall: \\( \\frac{\\text{TP}}{\\text{TP + FN}} \\)\n",
    "  - F1 Score: \\( \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision + Recall}} \\)\n",
    "\n",
    "### Q7. Choosing Evaluation Metric:\n",
    "\n",
    "- **Importance:**\n",
    "  - Depends on the problem context and the consequences of false positives/negatives.\n",
    "  - Precision-Recall Trade-off.\n",
    "\n",
    "### Q8. Precision as the Most Important Metric:\n",
    "\n",
    "- **Example: Email Spam Detection**\n",
    "  - **Scenario:** Classifying emails as spam or not.\n",
    "  - **Importance:** Minimize false positives (non-spam emails marked as spam).\n",
    "  - **Metric:** Precision is crucial; sacrificing some recall for high precision.\n",
    "\n",
    "### Q9. Recall as the Most Important Metric:\n",
    "\n",
    "- **Example: Medical Diagnosis**\n",
    "  - **Scenario:** Detecting a severe medical condition.\n",
    "  - **Importance:** Minimize false negatives (missing a positive case).\n",
    "  - **Metric:** Recall is crucial; accepting some false positives for high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f8ebc-9b5c-4bbf-9992-cc3a0bbd0c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
